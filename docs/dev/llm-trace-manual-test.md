- LLM Trace section visible and expandable in dev console
- Entries render newest-first
- Each entry expands to show Prompt Sent (pretty JSON + copy), Tools (args/output/error), Assistant Output (raw text + copy)
- Open `/chat` → LLM Trace section present
- Send a message → new trace entry with prompt payload
- Tool calls appear in trace with args + output + error when applicable
- Prompt payload shows Authorization header redacted in tools snapshot
- Prompt payload handles Headers/Map/Set/Date values without errors
- Prompt payload handles circular references without crashing
